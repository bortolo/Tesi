\chapter{Resolution of the system}

\section{Iteration algorithms}

The high nonlinear nature of the problem 	makes an analytical treatment very difficult, if not even impossible. For this reason, numerical schemes must be used to compute an approximate solution of the system \referenzaeq{eq: stationary problem}. Indisputably, the most used algorithms are \textit{the fully coupled Newton's method} and \textit{the decoupled Gummel map}. We spent only few words on the former as we implemented the latter, but first of all let us introduce a suitable linearization of the stationary DD equations. We can consider \referenzaeq{eq: stationary problem} in a more compact form:

\begin{equation}
\label{eq: abstract problem fully}
\vect{F(U)}=\vect{0}
\end{equation}

where:

\begin{equation}
\vect{U}:=[\varphi,n,p]^T \psp{30} \vect{F(U)}:=\left[ \begin{array}{c}
F_1(\vect{U}) \\
F_2(\vect{U}) \\
F_3(\vect{U})
\end{array}
\right]
\end{equation}

and having set:

\begin{align*}
F_1(\vect{U}) & = \nabla \cdot (-\epsilon \nabla \varphi) - q(p-n+N_D^+-N_A^-) \\
F_2(\vect{U}) & = \nabla \cdot ( - q\mu_n n \nabla \varphi + qD_n \nabla n )-qR \\
F_3(\vect{U}) & = \nabla \cdot (- q\mu_p p \nabla \varphi - qD_p \nabla p )+qR
\end{align*}

\vspace{0.1cm}

Basically the fully coupled Newton's method is an extension to differential operators of the well known Newton's method for the search of a zero for real functions ($f:\mathbb{R}\rightarrow \mathbb{R}$). In fact the vector function $\vect{F}$ is a nonlinear differential operator and the associated problem which we intend to resolve is: given a functional space $V$ and the operator $\vect{F}:V\rightarrow V$, find $\vect{U}\in V$ such that \referenzaeq{eq: abstract problem fully} is satisfied.
Just for the moment we don't care about the identity of $V$, which we will treat in details in the next section; now we are able to define  the abstract Newton's Method for the iterative solution of problem \referenzaeq{eq: stationary problem}:

\mybox{
\vspace{0.1cm}
Given $\vect{U}^0\in V$, for all $k\geq 0$ until convergence, solve the following linearized problem: 

\begin{equation}
\label{eq: abstract newton's method}
\begin{array}{c}
\vect{F'}(\vect{U}^k)\delta\vect{U}^k=-\vect{F}(\vect{U}^k) \\
\vect{U}^{k+1} = \vect{U}^k + \delta \vect{U}^k
\end{array}
\end{equation}
where $\vect{F'}$ is the Jacobian matrix of $\vect{F}$, whose $(i,j)$-th entry represents the Frech\`et derivative of the $i$-th row with respect to the $j$-th variable.
}{\textbf{Fully Coupled Newton's Method}}

\vspace{0.1cm}

The main advantage of this approach is without doubt the existence of the sequent theorem:

\begin{Teorema}
\label{theorem: newton convergence}
Let  $\vect{U}\in V$ be a solution of problem \referenzaeq{eq: abstract problem fully}. Assume that $\vect{F'}$ is Lipschitz continuos in the ball $\mathcal{B}(\vect{U},\delta)$, i.e., that there exists  $K>0$ such that:
\begin{equation}
||\vect{F'}(\vect{v})-\vect{F'}(\vect{z})||_{L(V,V)} \leq K ||\vect{v}-\vect{z}||_V \psp{10} \forall \vect{v},\vect{z} \in \mathcal{B}(\vect{U},\delta), \, \vect{v}\neq \vect{z}
\end{equation}
Then there exists in correspondence $\delta '>0$, with $\delta '\leq\delta$, such that for all $\vect{U}^0 \in \mathcal{B}(\vect{U},\delta ')$ the sequence $\left\{ \vect{U}^k \right\}$ generated by \referenzaeq{eq: abstract newton's method} converges quadratically to $\vect{U}$, i.e., there exists $C>0$ such that, for a suitable $k_0\geq 0$ we have:
\begin{equation}
\label{eq: convergece newton}
||\vect{U}-\vect{U}^{k+1}||_V\leq C||\vect{U}-\vect{U}^k||_V^2 \psp{15} \forall k\geq k_0
\end{equation}
\end{Teorema}

Even the presence of this impressive result there are are several issues which must be evaluated before move toward this way of resolution:
\begin{itemize}
\item the jacobian matrix $\vect{F'}$ is often quite ill-conditioned and needs appropriate scaling and balancing in order to avoid problems associated with round-off error;
\item to ensure convergence of the Newton iterative process \referenzaeq{eq: abstract newton's method}, it is particularly important to ensure a very good initial guess for the unknown variables $\vect{U}$;
\item if a direct solver is adopted (for example based on the LU factorization method), the number of loating point operations is of the order of  $N_{dofs}^3$, where $N_{dofs}$ is the number of degree of freedom used for the numerical approximation.
\end{itemize}

The fully coupled method is not the only possible approach, and many of the above points will be fixed adopting different methods, however theorem \referenzaeq{theorem: newton convergence} guarantees the best error convergence estimation.

\subsection{Gummel map algorithm}

In 1964 H. K. Gummel proposed an orginal iterative algorithm in order to solve the system \referenzaeq{eq: stationary problem} in a semiconductor device in one spatial dimension. Today the Gummel decoupled iterative algorithm has become a milestone in contemporary device simulation in industrial software for the design and analysis of semiconductor devices.

The main idea of the algorithm is to move the nonlinearity to the Poisson equation only and once obtained the electric potential profile, both continuity equations are linearized.  More precisely give an initial guess for $\varphi$, $n$ and $p$, the functional iteration consists in the succesive solution of the nonlinear Poisson's equation (NLP) in a inner loop (Newton's method is applyed for this equation) and of the two linearized continuity equations (DD electrons and DD holes). 
A concisely scheme is presented in \figref{fig: gummel map}.

Unfortunately there isn't any convergence result for this method like \referenzaeq{theorem: newton convergence}, although there are several advantages which make Gummel map algorithm preferable to the Fully Coupled Newton's Method.
In fact simulations experience shows that the Gummel process is much more insesitive to the choice of the initial guess than Newton's method. This is particularly important in multidimensional problems where it is far from trivial to design a good starting point for initializing in a favorable manner.

Another attractive feature is the reduced computational and memory stage cost: at each iteration step, the Newton algorithm requires assembling a Jacobian matrix of size $3N_{dof}\times 3N_{dof}$, while the Gummel algorithm requires the successive solution of three problems, each one of size equal to $N_{dof}\times N_{dof}$.

\subsubsection{FEMOS Gummel map}
After this short presentation of the qualities and the drawbacks of the Gummel decoupled algorithm, we propose our functional iteration. For the sake of simplicity let us consider some useful hypotesis:






\begin{figure}[!h]
\begin{center}
\begin{tikzpicture}
[scale=1.2]

\tikzstyle{NLP}=[rectangle,text width=3cm, align=center,draw, fill=gray!40];
\tikzstyle{DD}=[rectangle,text width=3cm,align=center,draw,fill=gray!10];
\tikzstyle{Normal}=[rectangle,fill=white];
\tikzstyle{CYC}=[diamond,draw];
\useasboundingbox (0,1) rectangle (8,9.5);
\draw [thick] (-0.5,1.0) rectangle (8.5,9.5);
%main boxes
\node [Normal] (v0) at (1,8) {$[\varphi,n,p]_{start}$};
\node [NLP] (v1) at (4,8) {\large NLP};
\node [CYC] (v2) at (4,7) {\small k};
\node [DD] (v3) at (4,5.5) {\large DD electrons};
\node [DD] (v4) at (4,4.0) {\large DD holes};
\node [CYC] (v5) at (4,2.5) {\small i};

%collegamenti
\draw [thick,->] (v0) -- (v1);
\draw [thick,->] (v1) -- (v2);
\draw [thick,->] (v2) -- (v3);
\draw [thick,->] (v3) -- (v4);
\draw [thick,->] (v4) -- (v5);
\draw [thick,->] (v5)--(7,2.5)--(7,9)--(4,9)--(v1);
\draw [thick,->] (v2)--(6,7)--(6,8)--(v1);
\draw [thick,->] (v5)--(4,1.5);

%note
\node [Normal] (v6) at (5.5,7.3) {$\varphi^{k+1}$};
\node [Normal] (v6) at (4.5,6.2) {$\varphi_{i+1}$};
\node [Normal] (v6) at (4.5,4.7) {$n_{i+1}$};
\node [Normal] (v6) at (4.5,3.2) {$p_{i+1}$};
\node [Normal] (v0) at (5.0,1.8) {$[\varphi,n,p]_{end}$};
\end{tikzpicture}
\caption{Gummel map algorithm}
\label{fig: gummel map}
\end{center}
\end{figure}


\begin{itemize}
\item we consider a polygonal simulation domain  in $\mathbb{R}^3$, denoted with $\Omega$; we indicate also with $\Omega_s$ the subset of $\Omega$ characterized by semiconductor material;
\item the domain is formed only by semiconductor and/or oxide material (typically we consider silicon and $SiO_2$);
\item contacts are assumed to be ideal, i.e. they are equipotential surfaces and no voltage drop occurs at the interface between the contact and the neighbouring material.
\end{itemize}
Take into account these considerations the appropriate Gummel map in our cases is the sequent:




\mybox{
Given $n^0$ and $p^0$, $\forall i$ until convergence:

\vspace{0.5cm}

(Step 0) Compute $\varphi_n^i$ and $\varphi_p^i$ with \referenzaeq{eq: n density mb} and \referenzaeq{eq: p density mb} and give a suitable initial guess for $\varphi^0_i$.

\vspace{0.5cm}

(Step 1) Solve the nonlinear Poisson equation over all the domain (NLP):

{
\footnotesize
\begin{equation}
\label{eq: NLP system}
\begin{cases}
\nabla \cdot (-\epsilon \nabla \varphi) + n_i\left( exp\left(\dfrac{\varphi-\varphi_n^i}{V_{th}}\right) - exp\left(\dfrac{\varphi_p^i-\varphi}{V_{th}}\right) \right)  =  q(N_D^+-N_A^-) & in \psp{3} \Omega_s \\
\nabla \cdot (-\epsilon \nabla \varphi)  =  0 & in \psp{3} \Omega / \Omega_s
\\
\varphi = \varphi_D & on \psp{3} \Gamma_D
\\
\nabla \varphi \cdot \vect{n} = 0 & on \psp{3} \Gamma_N 
\end{cases}
\end{equation}
}

Set $\varphi^i=\varphi$.

\vspace{0.5cm}

(Step 2) Solve the Linear Electron Contintuity Equation (LEC):
{
\small
\begin{equation}
\label{eq: LEC system}
\begin{cases}
 \nabla \cdot ( - q\mu_n n \nabla \varphi^i + qD_n \nabla n ) = qR(n^{i-1},p^{i-1}) & in \psp{3} \Omega_s
 \\
 n = n_D & on \psp{3} \Gamma_D
 \\
 \nabla n \cdot \vect{n} = 0 & on \psp{3} \Gamma_N
\end{cases}
\end{equation}
}
Set $n^i=n$.

\vspace{0.5cm}

(Step 3) Solve the Linear Hole Contintuity Equation (LHC):
{
\small
\begin{equation}
\label{eq: LHC system}
\begin{cases}
\nabla \cdot (- q\mu_p p \nabla \varphi^i - qD_p \nabla p ) =  -qR(n^{i-1},p^{i-1}) & in \psp{3} \Omega_s
\\
 p = p_D & on \psp{3} \Gamma_D
 \\
 \nabla p \cdot \vect{n} = 0 & on \psp{3} \Gamma_N
\end{cases}
\end{equation}
}
Set $p^i=p$.

\vspace{0.5cm}

(Step 4) If the convergence criterion is satisfied break, otherwise restart from step 0.

}{\textbf{FEMOS Gummel Map}}

\textcolor{red}{commenti a queste ipotesi magari si possiamo lavorarci sopra}
The second hypotesis excludes from our simulations only metal materials but there isn't any problem if some subset of the domain is formed by metal, it's possbile implement a more general formulation of the Poisson equation which it's presented in \textcolor{red}{referenza silvia}.
We fixed the third hypostesis because Robin conditions are not performed yet for this part of the code, but a suitable extension it's a n exercise.
 
\textcolor{red}{Dobbiamo parlare delle slotboom variables e della possibilitÃ  di usare i quasi fermi?????}
It's interesting note that carrier densities are not the only useful variables. As we introduced in section \referenzaeq{subsub:driftdiffusion transport}, current density may be represented in many different ways.  We underlie this because for example one can solve system \referenzaeq{eq: stationary problem} with Slotboom variables, without any change in the structure of the Gummel map.


\section{Finite element discretization}

In this section we describe the finite element discretization of the differential subproblems involved in the Gummel map previously introduced. Moreover for each kind of PDE problem we give a briefly presentation of the well-posedness analysis. 


\subsection{Weak Formulation}

We introduce the weak formulation used for the above equations accordingly to the classical displacement approach. We work with the sequent family of Sobolev functional spaces:

\begin{align}
H^m(\Omega) & := \left\{  v \in L^m(\Omega) : D^\alpha \in L^m(\Omega) \, \forall \alpha, |\alpha|\leq m\right\}
\\
H^m_{\Gamma}(\Omega) & := \left\{  v \in H^m(\Omega) : v|_{\Gamma} = 0 \right\}
\end{align} 

provided with the usual norm and seminorm $|| v ||_{m,\Omega}$ and $|v|_{m,\Omega}$.
In order to prove the existence and uniqueness of the solutions of the variational problems which will be introduced in the next sections, we apply the Lax-Milgram theorem \cite{salsa:EDP} to the weak formulations.

\input{contents/NonLinearPoisson}

\input{contents/ContinuityEquation}

\subsection{Geometrical discretization}

In view of the Galerkin finite element discretization of probems \referenzaeq{eq: NLP system}, \referenzaeq{eq: LEC system} and \referenzaeq{eq: LHC system}, we introduce some useful notations.

We let $\bar{\Omega} =  \bigcup \bar{K}$ be a partition $\mathcal{T}_h$ of the domain $\Omega$ into tetrahedral elements $K$ of volume $|K|$, i.e. we suppose that there exists a constant $\delta>0$ such that:
\begin{equation}
\label{eq: mesh regular condition}
\dfrac{h_K}{\rho_K} \leq \delta \psp{15} \forall K \in \mathcal{T}_h
\end{equation}

where $h_k=diam(K)=max_{x,y\in K}|x-y|$ and $\rho_K$ is the diameter of the sphere inscribed in the tetrahedral $K$. Condition \referenzaeq{eq: mesh regular condition} is the so called \textit{mesh regularity condition} \cite{quarteroni:modnum} and it ensures an istropic partition.
We denote with $\mathcal{E}_h$, $\mathcal{V}_h$ and $\mathcal{F}_h$ the set of all the edges, verteces and faces  
of $\mathcal{T}_h$ respectively, and for each $K\in \mathcal{T}_h$ we denote by $\partial K$ and $\vect{n}_{\partial K}$ the boundary of the element and its outward unit normal.
  
\subsection{Numerical approximation}

Let us introduce the general finite element space constitute by the polynomial element-wise defined functions:

\begin{equation}
X^r_h:= \{v_h \in C^0(\bar{\Omega}): v_h|_K\in \mathbb{P}_r,\forall K \in \mathcal{T}_h \}, \psp{10} r = 1,2, . \, . \, .
\end{equation}

More precisely for our purposes we decide to use the space $X^1_h$, which is a suitable discretization of $H^1(\Omega)$.  




\subsubsection{Damping}
The main problem associated with the classical Newton method is the tendency to overestimate the length of the actual correction step for the iterate. This phenomenon is frequently termed overshoot. In the case of the semiconductor equations this overshoot problem has often been treated by simply limiting the size of the correction vector ($\delta \varphi$) determined by Newton's method. The usual established modifications to avoid overshoot are given by the seguent formulations:


\begin{align}
A(\varphi_k)&=\dfrac{1}{t_k}F'(\varphi_k) \label{eq: NLP mod used} \\
A(\varphi_k)&=s_kI+F'(\varphi_k) \label{eq: NLP mod not used}
\end{align}

$t_k$ and $s_k$ are properly chosen positive parameters. During the implementation of the code we chose \referenzaeq{eq: NLP mod used} method. Note that for $t_k=1$, $s_k=0$ these modified Newton methods reduce to the classical Newton method. We have now to deal with the question how to choose $t_k$ or $s_k$ that the modified Newton methods exhibit superior convergence properties compared to the classical Newton method.
For the case \referenzaeq{eq: NLP mod used} there's a simple criterion suggested by Deuflhard \textcolor{red}{referenza}: $t_k$ is taken from the interval $(0,1]$ in such a manner that for any norm,
\begin{equation}
\label{eq: extended criterion}
||F'(\varphi_k)^{-1}F(\varphi_k-t_kF'(\varphi_k)^{-1}F(\varphi_k))||<||F'(\varphi_k)F(\varphi_k)||
\end{equation}

Condition \referenzaeq{eq: extended criterion} guarantees that the correction of the k-th iterate is an improved approximation to the final solution, in other words the residual norm can only descents.
This condition can be easily evaluated only if the Jacobian matrix is factored into triangular matrices because the evaluation of the argument of the norm on the left hand side of \referenzaeq{eq: extended criterion} is then reduced to a forward and backward substitution and the evaluation of $F(\varphi)$. Although we use an iterative methods (BCG solver) which implies serious diffuclties to the application of the criterion. Another valid possibility is to use the main diagonal of $F'(\varphi_k)$, denoted as $D(\varphi_k)$:
\begin{equation}
\label{eq: easy criterion}
||D(\varphi_k)^{-1}F(\varphi_k-t_kD(\varphi_k)^{-1}F(\varphi_k))||<||F'(\varphi_k)F(\varphi_k)||
\end{equation}

This is the criterion developed in our code. However the value to use for $t_k$ is a question of trial and error. Frequently one chooses the following sequences:

\begin{align}
t_k & = \dfrac{1}{2^i} \\
t_k & = \dfrac{1}{2^{\dfrac{i(i+1)}{2}}}  
\end{align}

obiuvsly $i$ is the subiterations of damping reached when satisfied \referenzaeq{eq: easy criterion}. Sufficiently close to the solution \referenzaeq{eq: extended criterion} (and so \referenzaeq{eq: easy criterion}) will be satisfied with $t_k=1$ so that the convergence properties of the classical Newton method are recovered.
 




\subsubsection{Numerical approximation}

  
\textcolor{blue}{Partiamo con una semidiscretizzazione spaziale e poi trattiamo anche quella temporale?}

\textcolor{blue}{Descrizione dettagliata (o meno?) del metodo implementato FVSG}

\subsection{Maximum discrete principle}
\textcolor{blue}{Scriviamo qualcosa in merito?Quanto approfondito?}




